{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 20 \n",
    "2. 20\n",
    "3. **a.10 b.10** c.10 d.10 e.20\n",
    "\n",
    "All these details can be found on Scientia. \n",
    "\n",
    "Your file should be \"Report.pdf\". \n",
    "\n",
    "You should not submit your code with your coursework. \n",
    "\n",
    "We will not check the code. \n",
    "\n",
    "Please submit only your results, comments and generated images. \n",
    "\n",
    "You can use any library for your implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer questions 3a-d, it is not necessary to rectify your images. However, if you choose to do it, please state it clearly. To find the salient points which meet the epipolar constraint, you just need to identify which pairs of matches satisfy the following condition (you can relax it by setting a low threshold instead of zero): \n",
    "\n",
    "(X′)^T*F*X = 0\n",
    " \n",
    "For question 3e, one way to estimate the area of the swimming pool and the length of the football field, is to find the 3D coordinates of their vertices. In that case, rectification should be applied to estimate disparity and then the 3D coordinates (X,Y,Z) for each vertex.\n",
    "\n",
    "Please describe the steps that you followed to estimate the pool area and the length of the football field. This will give you marks even if your final result is not correct.\n",
    "\n",
    "No need to use an appendix. Just add all your results in your report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = False\n",
    "do_plot = [False, False, False, False, True]\n",
    "\n",
    "w = 1920    # 图像宽\n",
    "h = 1080    # 图像长\n",
    "\n",
    "nfeatures = 0               # 最大关键点数量\n",
    "edgeThreshold = 3.1         # 过滤边缘响应的阈值(大于的剔除)\n",
    "contrastThreshold = 0.056   # 过滤低对比度关键点的阈值(小于的剔除)\n",
    "match_method = 'nndr'       # match method ['nndr', 'nn', 'cc']\n",
    "ratio_thresh = 0.7          # nndr比值阈值(大于的剔除)\n",
    "\n",
    "draw_match = -1\n",
    "flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS  # cv2.DRAW_MATCHES_FLAGS_DEFAULT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_T = np.array([[2/w, 0, -1],[0, 2/h, -1],[0, 0, 1],])\n",
    "\n",
    "intrinsic_param_1 = np.array(\n",
    "    [[1.600e+03, 0.000e+00, 9.595e+02], \n",
    "     [0.000e+00, 1.600e+03, 5.395e+02], \n",
    "     [0.000e+00, 0.000e+00, 1.000e+00]] \n",
    ")\n",
    "\n",
    "extrinsic_param_1 = np.array(\n",
    "    [[-6.32422984e-01, -7.74574101e-01, 8.72639567e-03, -2.36433081e+00], \n",
    "     [-5.00836670e-01, 4.00276423e-01, -7.67425179e-01, -1.74806440e+00], \n",
    "     [ 5.90934694e-01, -4.89707828e-01, -6.41079128e-01, 2.59576015e+01], \n",
    "     [ 0., 0., 0., 1.]]\n",
    ")\n",
    "\n",
    "intrinsic_param_2 = np.array(\n",
    "    [[1.49333333e+03, 0.00000000e+00, 9.78700000e+02], \n",
    "     [0.00000000e+00, 1.49333333e+03, 5.20300000e+02], \n",
    "     [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]\n",
    ")\n",
    "\n",
    "extrinsic_param_2 = np.array(\n",
    "    [[-0.5845883, -0.81050003, -0.03669427, -2.39520617], \n",
    "     [-0.5041514, 0.39832053, -0.76627171, -1.79913743], \n",
    "     [ 0.6356793, -0.42945388, -0.64146805, 26.26804151], \n",
    "     [ 0., 0., 0., 1.]]\n",
    ")\n",
    "\n",
    "distortion_1 = np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "distortion_2 = np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# 0.keypoint 标准化函数\n",
    "def normalize_points(pts):\n",
    "    if norm:\n",
    "        points_h = np.hstack([pts, np.ones((pts.shape[0], 1))])\n",
    "        normalized_points_h = (norm_T @ points_h.T).T\n",
    "        norm_points = normalized_points_h[:, :2]\n",
    "        return norm_points\n",
    "    return pts\n",
    "\n",
    "# 0.fundamental matrix 逆标准化函数\n",
    "def denormalize_FM(FM):\n",
    "    if norm:\n",
    "        return norm_T.T @ FM @ norm_T\n",
    "    return FM\n",
    "\n",
    "# 0.fundamental matrix 计算函数\n",
    "def compute_fundamental_matrix(intrinsic_param_1, extrinsic_param_1, intrinsic_param_2, extrinsic_param_2):\n",
    "    # Extract intrinsic matrices\n",
    "    K1 = intrinsic_param_1\n",
    "    K2 = intrinsic_param_2\n",
    "\n",
    "    # Extract extrinsic parameters\n",
    "    R1 = extrinsic_param_1[:3, :3]\n",
    "    t1 = extrinsic_param_1[:3, 3]\n",
    "    R2 = extrinsic_param_2[:3, :3]\n",
    "    t2 = extrinsic_param_2[:3, 3]\n",
    "\n",
    "    # Compute relative pose\n",
    "    R = R2 @ R1.T  # Relative rotation\n",
    "    t = t2 - R @ t1  # Relative translation\n",
    "    # print(f\"R_vec: {R}\")  #一样\n",
    "    # print(f\"T_vec: {t}\")  #一样\n",
    "\n",
    "    # Skew-symmetric matrix for t\n",
    "    t_skew = np.array([\n",
    "        [0, -t[2], t[1]],\n",
    "        [t[2], 0, -t[0]],\n",
    "        [-t[1], t[0], 0]\n",
    "    ])\n",
    "\n",
    "    # Compute the Fundamental Matrix\n",
    "    F = np.linalg.inv(K2).T @ t_skew @ R @ np.linalg.inv(K1)\n",
    "    \n",
    "    return F, R, t\n",
    "\n",
    "# 0.epipolar constraint 残差计算函数\n",
    "def check_epipolar_constraint(fundamental_matrix, pts1, pts2):\n",
    "    # Convert points to homogeneous coordinates\n",
    "    pts1_homogeneous = np.hstack([pts1, np.ones((pts1.shape[0], 1))])  # Nx3\n",
    "    pts2_homogeneous = np.hstack([pts2, np.ones((pts2.shape[0], 1))])  # Nx3\n",
    "\n",
    "    # Compute the epipolar constraint for each pair of points\n",
    "    residuals = []\n",
    "    for p1, p2 in zip(pts1_homogeneous, pts2_homogeneous):\n",
    "        # Compute the epipolar constraint: p2^T * F * p1\n",
    "        residual = np.dot(np.dot(p2, fundamental_matrix), p1)\n",
    "        residuals.append(abs(residual))  # Use absolute value for easy interpretation\n",
    "    return residuals\n",
    "\n",
    "# 0. Stereo image rectification\n",
    "def compute_disparity_and_rectification(frame1, frame2, intrinsic1, distortion1, intrinsic2, distortion2, R, T):\n",
    "    # Image dimensions\n",
    "    h, w = frame1.shape[:2]\n",
    "\n",
    "    # Stereo rectification transforms\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        intrinsic1, distortion1, intrinsic2, distortion2, (w, h), R, T,\n",
    "        flags=cv2.CALIB_ZERO_DISPARITY, alpha=1\n",
    "    )\n",
    "\n",
    "    # Compute rectification maps\n",
    "    map1x, map1y = cv2.initUndistortRectifyMap(\n",
    "        intrinsic1, distortion1, R1, P1, (w, h), cv2.CV_32FC1\n",
    "    )\n",
    "    map2x, map2y = cv2.initUndistortRectifyMap(\n",
    "        intrinsic2, distortion2, R2, P2, (w, h), cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    # Apply rectification\n",
    "    rectified1 = cv2.remap(frame1, map1x, map1y, cv2.INTER_LINEAR)\n",
    "    rectified2 = cv2.remap(frame2, map2x, map2y, cv2.INTER_LINEAR)\n",
    "\n",
    "    # Compute disparity using StereoBM\n",
    "    stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)\n",
    "    disparity = stereo.compute(rectified1, rectified2).astype(np.float32) / 16.0\n",
    "\n",
    "    return rectified1, rectified2, disparity\n",
    "\n",
    "# 1. Plot the detected features on the provided pair of frames\n",
    "def draw_keypoints(frame, keypoints):\n",
    "    frame_color = cv2.merge((frame,frame,frame))\n",
    "\n",
    "    for kp in keypoints:\n",
    "        # 获取关键点的圆心位置\n",
    "        x = int(kp.pt[0])\n",
    "        y = int(kp.pt[1])\n",
    "        random_color = tuple(np.random.randint(0, 255, size=3).tolist())\n",
    "\n",
    "        if flags == cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS:\n",
    "            # 获取关键点的大小作为半径\n",
    "            radius = int(kp.size / 2)  # Scale is proportional to size\n",
    "            # 获取带方向的关键点\n",
    "            angle = np.deg2rad(kp.angle)  # 方向角转换为弧度\n",
    "            length = radius  # 方向线长度\n",
    "            x2 = int(x + length * np.cos(angle))\n",
    "            y2 = int(y + length * np.sin(angle))\n",
    "\n",
    "            # 在图像上绘制圆形表示关键点及其大小\n",
    "            cv2.circle(frame_color, (x, y), radius=4, color=random_color, thickness=-1)\n",
    "            cv2.circle(frame_color, (x, y), radius=radius, color=random_color, thickness=2)\n",
    "            if type(x2) is int:\n",
    "                cv2.line(frame_color, (x, y), (x2, y2), color=random_color, thickness=2)\n",
    "            else:\n",
    "                cv2.line(frame_color, (x, y), (x2[0], y2[0]), color=random_color, thickness=2)\n",
    "                for _x2, _y2 in zip(x2[1:],y2[1:]):\n",
    "                    random_color = tuple(np.random.randint(0, 255, size=3).tolist())\n",
    "                    cv2.line(frame_color, (x, y), (_x2, _y2), color=random_color, thickness=2)\n",
    "        else:\n",
    "            cv2.circle(frame_color, (x, y), radius=4, color=random_color, thickness=-1)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(frame_color)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# 2. Create a composite image for 2 frames (centered overlay image)\n",
    "def plot_match_centered_overlay(pts1, pts2, frame1, frame2):\n",
    "    frame1_color = (173/255, 216/255, 230/255)\n",
    "    frame2_color = (255/255, 182/255, 193/255)\n",
    "    \n",
    "    frame1_blue = cv2.merge(((frame1*frame1_color[0]).astype(np.uint8),(frame1*frame1_color[1]).astype(np.uint8),(frame1*frame1_color[2]).astype(np.uint8)))\n",
    "    frame2_red = cv2.merge(((frame2*frame2_color[0]).astype(np.uint8),(frame2*frame2_color[1]).astype(np.uint8),(frame2*frame2_color[2]).astype(np.uint8)))\n",
    "\n",
    "    # Manually draw matches on the composite image\n",
    "    composite_with_matches = cv2.addWeighted(frame1_blue, 0.8, frame2_red, 0.8, 0)\n",
    "    for pt1, pt2 in zip(pts1[:draw_match],pts2[:draw_match]):\n",
    "        pt1 = tuple(map(int, pt1))\n",
    "        pt2 = tuple(map(int, pt2))\n",
    "        cv2.circle(composite_with_matches, pt1, 8, (0, 255, 0), -1)     # keypoint1-green\n",
    "        cv2.circle(composite_with_matches, pt2, 8, (255, 0, 0), -1)     # keypoint2-red\n",
    "        cv2.line(composite_with_matches, pt1, pt2, (255, 255, 0), 2)\n",
    "\n",
    "    # Display the centered overlay with matches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(composite_with_matches)\n",
    "    plt.axis(\"off\")\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='none', label='Keypoints in Frame1', markerfacecolor=(0.,1.,0.), markersize=12),    #green\n",
    "        Line2D([0], [0], marker='o', color='none', label='Keypoints in Frame2', markerfacecolor=(1.,0.,0.), markersize=12),    #red\n",
    "    ]\n",
    "    plt.legend(handles=legend_handles, loc='lower right', fontsize='large')\n",
    "    plt.show()\n",
    "\n",
    "# 3. Create a composite image for 2 frames (side-by-side image)\n",
    "def plot_match_side_by_side(pts1, pts2, frame1, frame2):\n",
    "    height1, width1 = frame1.shape\n",
    "    height2, width2 = frame2.shape\n",
    "    canvas = np.zeros((max(height1, height2), width1 + width2, 3), dtype=np.uint8)\n",
    "\n",
    "    # Place the colored images side by side on the canvas\n",
    "    canvas[:height1, :width1] = cv2.merge((frame1, frame1, frame1))\n",
    "    canvas[:height2, width1:] = cv2.merge((frame2, frame2, frame2))\n",
    "\n",
    "    # Manually draw matches on the composite image\n",
    "    for pt1, pt2 in zip(pts1[:draw_match],pts2[:draw_match]):\n",
    "        pt1 = tuple(map(int, pt1))\n",
    "        pt2 = tuple(map(int, pt2))\n",
    "        pt2 = (pt2[0] + width1, pt2[1]) #Offset pt2 coordinates because img2 is placed to the right of img1\n",
    "        \n",
    "        cv2.line(canvas, pt1, pt2, (225,225,0), thickness=2)\n",
    "        cv2.circle(canvas, pt1, radius=10, color=(0,225,0), thickness=-1)\n",
    "        cv2.circle(canvas, pt2, radius=10, color=(225,0,0), thickness=-1)\n",
    "\n",
    "    # Display the centered overlay with matches\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis(\"off\")\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='none', label='Keypoints in Frame1', markerfacecolor=(0.,1.,0.), markersize=12),    #green\n",
    "        Line2D([0], [0], marker='o', color='none', label='Keypoints in Frame2', markerfacecolor=(1.,0.,0.), markersize=12),    #red\n",
    "    ]\n",
    "    plt.legend(handles=legend_handles, loc='lower right', fontsize='large')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load images and get keypoints/descriptors \"\"\"\n",
    "# Load the uploaded images\n",
    "frame1_path = \"./Frame1.png\"\n",
    "frame2_path = \"./Frame2.png\"\n",
    "ori_frame1 = cv2.imread(frame1_path)\n",
    "ori_frame2 = cv2.imread(frame2_path)\n",
    "\n",
    "# Convert images to grayscale\n",
    "gray_frame1 = cv2.cvtColor(ori_frame1, cv2.COLOR_BGR2GRAY)\n",
    "gray_frame2 = cv2.cvtColor(ori_frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "frame1 = gray_frame1\n",
    "frame2 = gray_frame2\n",
    "\n",
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create(nfeatures = nfeatures, contrastThreshold = contrastThreshold, edgeThreshold = edgeThreshold,)\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(frame1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(frame2, None)\n",
    "\n",
    "print(f\"Number of keypoints in frame1: {len(keypoints1)}\")\n",
    "print(f\"Number of keypoints in frame2: {len(keypoints2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Match the detected salient features \"\"\"\n",
    "if match_method == 'nndr':\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:  # 比值测试\n",
    "            good_matches.append(m)\n",
    "    matches = sorted(good_matches, key=lambda x: x.distance)\n",
    "elif match_method == 'nn':\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "elif match_method == 'cc':\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "print(f\"({match_method.upper()}) Number of matches: {len(matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Estimate the fundamental matrix (using matched features) \"\"\"\n",
    "# Convert keypoints to numpy arrays\n",
    "pts1 = normalize_points(np.float32([keypoints1[m.queryIdx].pt for m in matches]))\n",
    "pts2 = normalize_points(np.float32([keypoints2[m.trainIdx].pt for m in matches]))\n",
    "\n",
    "# Estimate the fundamental matrix using RANSAC to handle outliers\n",
    "ransec_threshold = 20/1920 if norm else 20\n",
    "F_match_ori, mask = cv2.findFundamentalMat(\n",
    "    pts1, pts2, method=cv2.FM_RANSAC,\n",
    "    ransacReprojThreshold = ransec_threshold,\n",
    "    confidence = 0.999999,\n",
    "    maxIters = 10000\n",
    ")\n",
    "\n",
    "# Filter inliers using the mask\n",
    "inliers_pts1 = pts1[mask.ravel() == 1]\n",
    "inliers_pts2 = pts2[mask.ravel() == 1]\n",
    "print(f\"Number of inliers: {len(inliers_pts1)} / {len(pts1)}\")\n",
    "\n",
    "F_match_ori = denormalize_FM(F_match_ori)\n",
    "print(\"\\nEstimated Fundamental Matrix (using matches):\\n\", F_match_ori)\n",
    "\n",
    "# Refine the Fundamental Matrix using only inliers\n",
    "F_match, mask_refined = cv2.findFundamentalMat(inliers_pts1, inliers_pts2, method=cv2.FM_8POINT)\n",
    "F_match = denormalize_FM(F_match)\n",
    "print(\"\\nRefined Fundamental Matrix (using matches):\\n\", F_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Estimate the fundamental matrix (using camera parameters) \"\"\"\n",
    "F_param, _, _ = compute_fundamental_matrix(intrinsic_param_1, extrinsic_param_1, intrinsic_param_2, extrinsic_param_2)\n",
    "print(\"Fundamental Matrix (using params):\\n\", F_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Verify the epipolar constraint for a set of matching keypoints \"\"\"\n",
    "pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
    "pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "# Check epipolar constraint\n",
    "residuals_match = np.array(check_epipolar_constraint(F_match, pts1, pts2))\n",
    "residuals_param = np.array(check_epipolar_constraint(F_param, pts1, pts2))\n",
    "residuals_match_ori = np.array(check_epipolar_constraint(F_match_ori, pts1, pts2))\n",
    "\n",
    "# Output results\n",
    "threshold = 0.01\n",
    "print(f\"|       |{'':9}mean{'':8}|{'':9}std{'':9}|{'':9}var{'':9}|{'':9}min{'':9}|{'':9}max{'':9}| inliers\")\n",
    "for data, name in zip([residuals_param,residuals_match_ori,residuals_match,],['param','m_ori','match',]):\n",
    "    inliers = [i for i, r in enumerate(data) if r < threshold]\n",
    "    print(f\"| {name} | {data.mean():.17f} | {data.std():.17f} | {data.var():.17f} | {data.min():.17f} | {data.max():19.16f} | {len(inliers):2} / {len(data):2}\")\n",
    "\n",
    "# for i, (residual_match,residual_param) in enumerate(zip(residuals_match,residuals_param)):\n",
    "#     print(f\"Point Pair {(i + 1):3}: {residual_match:20.17f} | {residual_param:20.17f} | {abs(residual_match-residual_param):20.17f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Select Corner Points in Rectified Frame manually \"\"\"\n",
    "import pickle as pk\n",
    "\n",
    "# 0.Compute rectification and disparity\n",
    "_, R, T = compute_fundamental_matrix(intrinsic_param_1, extrinsic_param_1, intrinsic_param_2, extrinsic_param_2)\n",
    "rectified1, rectified2, disparity_map = compute_disparity_and_rectification(frame1, frame2, intrinsic_param_1, distortion_1, intrinsic_param_2, distortion_2, R, T)\n",
    "\n",
    "pk.dump(rectified1,open('./data/rectified1.pkl','wb'))\n",
    "pk.dump(rectified2,open('./data/rectified2.pkl','wb'))\n",
    "pk.dump(disparity_map,open('./data/disparity_map.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.Set informations from frame2\n",
    "focal_length = intrinsic_param_1[0,0]  # in pixels\n",
    "baseline = np.linalg.norm(T)    # distance between the two cameras\n",
    "cx = intrinsic_param_1[0,2]     # principal point coordinates\n",
    "cy = intrinsic_param_1[1,2]     # principal point coordinates\n",
    "\n",
    "\n",
    "# 1.Set Corner Points in Pixel Coordinates (in rectified frame1)\n",
    "swimming_pool_corners_2D = np.array([[587, 621], [1185, 900]])\n",
    "football_touchline_2D = np.array([[1135, 683], [1671, 370]])\n",
    "# swimming_pool_corners_2D = np.array([[487, 620], [1014, 897]])    #2\n",
    "# football_touchline_2D = np.array([[985, 700], [1565, 349]])       #2\n",
    "\n",
    "\n",
    "# 2.Calculate Depth Using Disparity Map\n",
    "def disparity_to_depth(disparity, focal_length, baseline):\n",
    "    if disparity <= 0:\n",
    "        return -1\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        depth = focal_length * baseline / disparity\n",
    "    return depth\n",
    "swimming_pool_corners_depth = [disparity_to_depth(disparity_map[int(v), int(u)], focal_length, baseline) for u, v in swimming_pool_corners_2D]\n",
    "football_touchline_depth = [disparity_to_depth(disparity_map[int(v), int(u)], focal_length, baseline) for u, v in football_touchline_2D]\n",
    "\n",
    "\n",
    "# 3.Reconstruct 3D Points\n",
    "def reconstruct_3D(points_2D, depths, focal_length, cx, cy):\n",
    "    points_3D = []\n",
    "    uni_depth = np.max(depths)\n",
    "    for (u, v), d in zip(points_2D, depths):\n",
    "        if d > 0:\n",
    "            Z = d\n",
    "            X = (u - cx) * Z / focal_length\n",
    "            Y = (v - cy) * Z / focal_length\n",
    "            points_3D.append([X, Y, Z])\n",
    "        else:\n",
    "            points_3D.append([np.nan, np.nan, np.nan])  # Handle invalid points\n",
    "    return np.array(points_3D)\n",
    "swimming_pool_corners_3D = reconstruct_3D(swimming_pool_corners_2D, swimming_pool_corners_depth , focal_length, cx, cy)\n",
    "football_touchline_3D = reconstruct_3D(football_touchline_2D, football_touchline_depth, focal_length, cx, cy)\n",
    "print(swimming_pool_corners_3D)\n",
    "print(football_touchline_3D)\n",
    "\n",
    "# 4.Compute Area and Length\n",
    "def compute_rectangle_area(point1_3D, point2_3D):\n",
    "    # Extract coordinates\n",
    "    x1, y1, z1 = point1_3D\n",
    "    x2, y2, z2 = point2_3D\n",
    "\n",
    "    # Length and width (assuming rectangle aligned to axes or known plane)\n",
    "    length = abs(x2 - x1)\n",
    "    width = abs(y2 - y1)\n",
    "\n",
    "    # Compute the area\n",
    "    area = length * width\n",
    "    return area\n",
    "\n",
    "def compute_length(point1_3D, point2_3D):\n",
    "    return np.linalg.norm(point1_3D - point2_3D)\n",
    "\n",
    "# Compute area of the swimming pool\n",
    "pool_area = compute_rectangle_area(swimming_pool_corners_3D[0],swimming_pool_corners_3D[1])\n",
    "print(f\"Estimated swimming pool area: {pool_area:.2f} square meters\")\n",
    "\n",
    "# Compute length of the football field touchline\n",
    "touchline_length = compute_length(football_touchline_3D[0], football_touchline_3D[1])\n",
    "print(f\"Estimated touchline length: {touchline_length:.2f} meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" !Plot figures\"\"\"\n",
    "# !PLOT-1: Plot the detected features on the provided pair of frames\n",
    "if do_plot[0]:\n",
    "    for frame, keypoints in zip([frame1,frame2],[keypoints1,keypoints2]):\n",
    "        draw_keypoints(frame, keypoints)\n",
    "        \n",
    "# !PLOT-2: (centered overlay image) Create a composite image for 2 frames\n",
    "if do_plot[1] and frame1.shape == frame2.shape:\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
    "    plot_match_centered_overlay(pts1, pts2, frame1, frame2)\n",
    "\n",
    "# !PLOT-3: (side-by-side image) Create a composite image for 2 frames\n",
    "if do_plot[2]:\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
    "    plot_match_side_by_side(pts1, pts2, frame1, frame2)\n",
    "\n",
    "# !PLOT-4: Plot matches that meet the epipolar constraint\n",
    "if do_plot[3]:\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
    "    residuals_match = np.array(check_epipolar_constraint(F_match, pts1, pts2))\n",
    "    residuals_param = np.array(check_epipolar_constraint(F_param, pts1, pts2))\n",
    "    residuals_match_ori = np.array(check_epipolar_constraint(F_match_ori, pts1, pts2))\n",
    "\n",
    "    threshold = 0.01\n",
    "    for data, name in zip([residuals_param,residuals_match_ori,residuals_match,],['F_param','F_match_ori','F_match',]):\n",
    "        inliers = [i for i, r in enumerate(data) if r < threshold]\n",
    "        print(f\"Inliers for {name}: {len(inliers):2}/{len(data):2}\")\n",
    "        plot_match_centered_overlay(pts1[inliers], pts2[inliers], frame1, frame2)\n",
    "        plot_match_side_by_side(pts1[inliers], pts2[inliers], frame1, frame2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" !Optional:  Illustrate the disparity map and the rectification result \"\"\"\n",
    "def draw_horizontal_lines(image, line_spacing=150, color=(255, 200, 0)):\n",
    "    image_with_lines = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    for y in range(0, h, line_spacing):\n",
    "        cv2.line(image_with_lines, (0, y), (w, y), color, thickness=2)\n",
    "    return image_with_lines\n",
    "\n",
    "if do_plot[4]:\n",
    "    # Compute rectification and disparity\n",
    "    _, R, T = compute_fundamental_matrix(intrinsic_param_1, extrinsic_param_1, intrinsic_param_2, extrinsic_param_2)\n",
    "    rectified1, rectified2, disparity = compute_disparity_and_rectification(frame1, frame2, intrinsic_param_1, distortion_1, intrinsic_param_2, distortion_2, R, T)\n",
    "\n",
    "    # Draw horizontal lines\n",
    "    rectified1_color =  cv2.merge((rectified1, rectified1, rectified1))\n",
    "    rectified2_color =  cv2.merge((rectified2, rectified2, rectified2))\n",
    "    rectified1_with_lines = draw_horizontal_lines(rectified1_color)\n",
    "    rectified2_with_lines = draw_horizontal_lines(rectified2_color)\n",
    "\n",
    "    # Combine the images horizontally for visualization\n",
    "    combined_image = np.hstack((rectified1_with_lines, rectified2_with_lines))\n",
    "\n",
    "    # Display the result using matplotlib\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    # plt.title(\"Rectified Images with Black Borders and Horizontal Lines\")\n",
    "    plt.imshow(combined_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    # plt.title(\"Disparity Map\")\n",
    "    plt.imshow(disparity, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
